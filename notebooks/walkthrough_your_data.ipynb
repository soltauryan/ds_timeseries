{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerator Walkthrough: Bringing Your Own Data\n",
    "\n",
    "This notebook walks you through using `ds_timeseries` as an accelerator for **your** dataset.  \n",
    "It builds from simple to complex:\n",
    "\n",
    "| Section | What You'll Do |\n",
    "|---------|---------------|\n",
    "| **1. Data Prep** | Load your data, map your fiscal calendar, validate |\n",
    "| **2. Baseline Models** | Naive, Moving Average, ETS |\n",
    "| **3. ML Models** | LightGBM, XGBoost, CatBoost |\n",
    "| **4. Advanced** | Prophet, Direct forecasting, DRFAM |\n",
    "| **5. Ensembles** | Simple, Weighted, Stacking |\n",
    "| **6. Hierarchical** | Reconciliation across Parent Customer / Profit Center |\n",
    "| **7. Scorecard** | Compare everything against your current predictions |\n",
    "\n",
    "---\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "- You have **weekly** sales data at the **Customer-Material** grain  \n",
    "- You have your company's **fiscal calendar** as a table (dates, week-end dates, fiscal months, etc.)  \n",
    "- You have **predictions from Nov 25** (FY start) that you want to benchmark against  \n",
    "- Train/test split: everything **before Nov 25** is train, **Nov 25 onward** is test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ds_timeseries imports\n",
    "from ds_timeseries.evaluation.metrics import wape, mae, rmse, bias, evaluate_forecast\n",
    "from ds_timeseries.data.validation import validate_data, classify_demand\n",
    "from ds_timeseries.features import (\n",
    "    FiscalCalendarConfig,\n",
    "    FeatureConfig,\n",
    "    add_fiscal_features,\n",
    "    engineer_features,\n",
    "    rollup_to_fiscal_month,\n",
    ")\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Preparation\n",
    "\n",
    "### 1a. Load your sales data\n",
    "\n",
    "The library expects three required columns:\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `unique_id` | str | One ID per time series (e.g. `\"CUST001_MAT123\"`) |\n",
    "| `ds` | datetime | Week-ending date |\n",
    "| `y` | float | Sales value (quantity or dollars) |\n",
    "\n",
    "Plus any hierarchy columns you want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS: Load your data ===\n",
    "# Examples:\n",
    "#   raw = pd.read_csv(\"path/to/weekly_sales.csv\")\n",
    "#   raw = pd.read_parquet(\"path/to/weekly_sales.parquet\")\n",
    "#   raw = pd.read_excel(\"path/to/weekly_sales.xlsx\")\n",
    "\n",
    "raw = pd.read_parquet(\"../data/raw/your_sales_data.parquet\")  # <-- replace\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Map your columns to the expected schema\n",
    "\n",
    "Rename whatever your columns are called into the standard names.\n",
    "\n",
    "**Hierarchy mapping for your business:**\n",
    "\n",
    "```\n",
    "Total\n",
    "└── Parent Customer   (your: \"parent_customer\", \"sold_to_group\", etc.)\n",
    "    └── Customer       (your: \"sold_to\", \"ship_to\", \"customer_number\")\n",
    "        └── Profit Center  (your: \"profit_center\", \"product_line\")\n",
    "            └── Material   (your: \"material\", \"sku\", \"item_number\")\n",
    "```\n",
    "\n",
    "The bottom level (`unique_id`) is the **Customer-Material** combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS: Map your column names ===\n",
    "\n",
    "df = raw.rename(columns={\n",
    "    # Required\n",
    "    \"week_end_date\": \"ds\",          # <-- your date column\n",
    "    \"sales_qty\": \"y\",               # <-- your target column\n",
    "\n",
    "    # Hierarchy (keep whatever you have)\n",
    "    \"parent_customer\": \"parent_customer_id\",\n",
    "    \"customer_number\": \"customer_id\",\n",
    "    \"profit_center\": \"profit_center_id\",\n",
    "    \"material\": \"material_id\",\n",
    "})\n",
    "\n",
    "# Ensure datetime\n",
    "df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "\n",
    "# Build unique_id from Customer + Material\n",
    "df[\"unique_id\"] = df[\"customer_id\"].astype(str) + \"_\" + df[\"material_id\"].astype(str)\n",
    "\n",
    "# Ensure y is numeric\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Series: {df['unique_id'].nunique()}\")\n",
    "print(f\"Date range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Bring your own fiscal calendar\n",
    "\n",
    "You said you have a table with dates, week-end dates, fiscal month numbers, etc.  \n",
    "The library needs these columns in the fiscal calendar:\n",
    "\n",
    "| Column | Type | Required | Notes |\n",
    "|--------|------|----------|-------|\n",
    "| `ds` | datetime | **Yes** | Must match your sales data dates exactly |\n",
    "| `fiscal_year` | int | **Yes** | e.g. 2026 |\n",
    "| `fiscal_month` | int | **Yes** | 1-12 within the fiscal year |\n",
    "| `fiscal_quarter` | int | Recommended | 1-4 |\n",
    "| `fiscal_week` | int | Recommended | 1-52 within the fiscal year |\n",
    "| `fiscal_week_in_month` | int | Recommended | 1-5 within the fiscal month |\n",
    "| `fiscal_week_in_quarter` | int | Optional | 1-13 within the quarter |\n",
    "| `is_fiscal_month_end` | bool | Recommended | Critical for hockey-stick patterns |\n",
    "| `is_fiscal_quarter_end` | bool | Optional | |\n",
    "| `is_fiscal_year_end` | bool | Optional | |\n",
    "\n",
    "Below, load your fiscal calendar and map the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS: Load your fiscal calendar ===\n",
    "\n",
    "fiscal_raw = pd.read_parquet(\"../data/raw/your_fiscal_calendar.parquet\")  # <-- replace\n",
    "# fiscal_raw = pd.read_csv(\"../data/raw/your_fiscal_calendar.csv\")\n",
    "# fiscal_raw = pd.read_excel(\"../data/raw/your_fiscal_calendar.xlsx\")\n",
    "\n",
    "print(\"Your fiscal calendar columns:\")\n",
    "print(fiscal_raw.columns.tolist())\n",
    "fiscal_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS: Map your fiscal calendar columns ===\n",
    "\n",
    "fiscal_cal = fiscal_raw.rename(columns={\n",
    "    \"week_end_date\": \"ds\",              # <-- your week-ending date column\n",
    "    \"fiscal_year_number\": \"fiscal_year\",\n",
    "    \"fiscal_month_number\": \"fiscal_month\",\n",
    "    \"fiscal_quarter_number\": \"fiscal_quarter\",\n",
    "    \"fiscal_week_number\": \"fiscal_week\",\n",
    "    # Add more mappings as needed\n",
    "})\n",
    "\n",
    "fiscal_cal[\"ds\"] = pd.to_datetime(fiscal_cal[\"ds\"])\n",
    "\n",
    "# --- Derive columns you might not have ---\n",
    "\n",
    "# If you don't have fiscal_week_in_month, derive it:\n",
    "if \"fiscal_week_in_month\" not in fiscal_cal.columns:\n",
    "    fiscal_cal[\"fiscal_week_in_month\"] = (\n",
    "        fiscal_cal\n",
    "        .groupby([\"fiscal_year\", \"fiscal_month\"])\n",
    "        .cumcount() + 1\n",
    "    )\n",
    "\n",
    "# If you don't have fiscal_week_in_quarter, derive it:\n",
    "if \"fiscal_week_in_quarter\" not in fiscal_cal.columns:\n",
    "    fiscal_cal[\"fiscal_week_in_quarter\"] = (\n",
    "        fiscal_cal\n",
    "        .groupby([\"fiscal_year\", \"fiscal_quarter\"])\n",
    "        .cumcount() + 1\n",
    "    )\n",
    "\n",
    "# If you don't have is_fiscal_month_end, derive it:\n",
    "# (last week in each fiscal month = month end)\n",
    "if \"is_fiscal_month_end\" not in fiscal_cal.columns:\n",
    "    max_week_in_month = (\n",
    "        fiscal_cal\n",
    "        .groupby([\"fiscal_year\", \"fiscal_month\"])[\"fiscal_week_in_month\"]\n",
    "        .transform(\"max\")\n",
    "    )\n",
    "    fiscal_cal[\"is_fiscal_month_end\"] = (\n",
    "        fiscal_cal[\"fiscal_week_in_month\"] == max_week_in_month\n",
    "    )\n",
    "\n",
    "if \"is_fiscal_quarter_end\" not in fiscal_cal.columns:\n",
    "    max_week_in_qtr = (\n",
    "        fiscal_cal\n",
    "        .groupby([\"fiscal_year\", \"fiscal_quarter\"])[\"fiscal_week_in_quarter\"]\n",
    "        .transform(\"max\")\n",
    "    )\n",
    "    fiscal_cal[\"is_fiscal_quarter_end\"] = (\n",
    "        fiscal_cal[\"fiscal_week_in_quarter\"] == max_week_in_qtr\n",
    "    )\n",
    "\n",
    "if \"is_fiscal_year_end\" not in fiscal_cal.columns:\n",
    "    max_week_in_year = (\n",
    "        fiscal_cal\n",
    "        .groupby(\"fiscal_year\")[\"fiscal_week\"]\n",
    "        .transform(\"max\")\n",
    "    )\n",
    "    fiscal_cal[\"is_fiscal_year_end\"] = (\n",
    "        fiscal_cal[\"fiscal_week\"] == max_week_in_year\n",
    "    )\n",
    "\n",
    "# Keep only the columns the library uses\n",
    "fiscal_cols = [\n",
    "    \"ds\", \"fiscal_year\", \"fiscal_quarter\", \"fiscal_month\", \"fiscal_week\",\n",
    "    \"fiscal_week_in_month\", \"fiscal_week_in_quarter\",\n",
    "    \"is_fiscal_month_end\", \"is_fiscal_quarter_end\", \"is_fiscal_year_end\",\n",
    "]\n",
    "fiscal_cal = fiscal_cal[[c for c in fiscal_cols if c in fiscal_cal.columns]].drop_duplicates(\"ds\")\n",
    "\n",
    "print(f\"Fiscal calendar: {len(fiscal_cal)} weeks, {fiscal_cal['ds'].min()} to {fiscal_cal['ds'].max()}\")\n",
    "fiscal_cal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that your fiscal calendar dates align with your sales data dates\n",
    "sales_dates = set(df[\"ds\"].dt.normalize())\n",
    "cal_dates = set(fiscal_cal[\"ds\"].dt.normalize())\n",
    "\n",
    "missing_from_cal = sales_dates - cal_dates\n",
    "if missing_from_cal:\n",
    "    print(f\"WARNING: {len(missing_from_cal)} sales dates not in your fiscal calendar!\")\n",
    "    print(f\"  First few: {sorted(missing_from_cal)[:5]}\")\n",
    "    print(f\"  This will cause NaN fiscal features. Fix your calendar or align dates.\")\n",
    "else:\n",
    "    print(\"All sales dates found in fiscal calendar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Validate your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = validate_data(df[[\"unique_id\", \"ds\", \"y\"]])\n",
    "\n",
    "print(f\"Valid: {validation.is_valid}\")\n",
    "if validation.errors:\n",
    "    print(f\"\\nErrors:\")\n",
    "    for e in validation.errors:\n",
    "        print(f\"  - {e}\")\n",
    "if validation.warnings:\n",
    "    print(f\"\\nWarnings:\")\n",
    "    for w in validation.warnings:\n",
    "        print(f\"  - {w}\")\n",
    "print(f\"\\nStats:\")\n",
    "for k, v in validation.stats.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify demand patterns - tells you which series are intermittent/lumpy\n",
    "demand_classes = classify_demand(df[[\"unique_id\", \"ds\", \"y\"]])\n",
    "\n",
    "print(\"Demand pattern distribution:\")\n",
    "print(demand_classes[\"category\"].value_counts())\n",
    "print()\n",
    "print(f\"Avg zero %: {demand_classes['zero_pct'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e. Define train/test split at fiscal year start (Nov 25)\n",
    "\n",
    "This is the critical split. Everything before your FY start is training data.  \n",
    "Everything from Nov 25 onward is the test period you'll compare models against your existing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS: Your fiscal year cutoff date ===\n",
    "CUTOFF_DATE = pd.Timestamp(\"2025-11-25\")\n",
    "\n",
    "# If your week-end dates don't land exactly on Nov 25, find the nearest one:\n",
    "all_dates = sorted(df[\"ds\"].unique())\n",
    "cutoff_idx = np.searchsorted(all_dates, CUTOFF_DATE)\n",
    "actual_cutoff = all_dates[cutoff_idx]  # first test date\n",
    "print(f\"Requested cutoff: {CUTOFF_DATE.date()}\")\n",
    "print(f\"Actual first test date: {pd.Timestamp(actual_cutoff).date()}\")\n",
    "\n",
    "train = df[df[\"ds\"] < actual_cutoff].copy()\n",
    "test = df[df[\"ds\"] >= actual_cutoff].copy()\n",
    "\n",
    "# How many weeks in the test period?\n",
    "test_weeks = test[\"ds\"].nunique()\n",
    "HORIZON = test_weeks\n",
    "\n",
    "print(f\"\\nTrain: {train['ds'].nunique()} weeks, {train['ds'].min().date()} to {train['ds'].max().date()}\")\n",
    "print(f\"Test:  {test_weeks} weeks, {test['ds'].min().date()} to {test['ds'].max().date()}\")\n",
    "print(f\"Series: {train['unique_id'].nunique()} in train, {test['unique_id'].nunique()} in test\")\n",
    "print(f\"\\nHORIZON = {HORIZON} weeks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f. Load your existing predictions (the benchmark to beat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS: Load your existing predictions ===\n",
    "# These are the forecasts your team made starting Nov 25\n",
    "\n",
    "existing_preds_raw = pd.read_parquet(\"../data/raw/your_predictions.parquet\")  # <-- replace\n",
    "\n",
    "# Map to standard format\n",
    "existing_preds = existing_preds_raw.rename(columns={\n",
    "    \"week_end_date\": \"ds\",\n",
    "    \"predicted_qty\": \"yhat\",\n",
    "    # map customer/material to build unique_id\n",
    "    \"customer_number\": \"customer_id\",\n",
    "    \"material\": \"material_id\",\n",
    "})\n",
    "existing_preds[\"ds\"] = pd.to_datetime(existing_preds[\"ds\"])\n",
    "existing_preds[\"unique_id\"] = (\n",
    "    existing_preds[\"customer_id\"].astype(str) + \"_\" + existing_preds[\"material_id\"].astype(str)\n",
    ")\n",
    "\n",
    "# Score your existing predictions against actuals\n",
    "benchmark = test.merge(existing_preds[[\"unique_id\", \"ds\", \"yhat\"]], on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "benchmark_wape = wape(benchmark[\"y\"], benchmark[\"yhat\"])\n",
    "benchmark_mae = mae(benchmark[\"y\"], benchmark[\"yhat\"])\n",
    "\n",
    "print(f\"Your existing predictions (benchmark to beat):\")\n",
    "print(f\"  WAPE: {benchmark_wape:.2%}\")\n",
    "print(f\"  MAE:  {benchmark_mae:.2f}\")\n",
    "print(f\"  Matched rows: {len(benchmark)} of {len(test)} test rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Baseline Models (Start Simple)\n",
    "\n",
    "Always start with baselines. They're fast, require no tuning, and set the floor.  \n",
    "If ML models can't beat these, the data doesn't have learnable patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.models import (\n",
    "    NaiveForecaster,\n",
    "    MovingAverageForecaster,\n",
    "    SeasonalNaiveForecaster,\n",
    "    ETSForecaster,\n",
    ")\n",
    "\n",
    "# We'll collect all results here\n",
    "results = {}\n",
    "\n",
    "def score_model(name, model, train_df, test_df, horizon):\n",
    "    \"\"\"Fit model, predict, score against test, store results.\"\"\"\n",
    "    model.fit(train_df)\n",
    "    preds = model.predict(horizon=horizon)\n",
    "\n",
    "    merged = test_df.merge(preds, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "    if len(merged) == 0:\n",
    "        print(f\"  {name}: No matching predictions! Check date alignment.\")\n",
    "        return None\n",
    "\n",
    "    scores = evaluate_forecast(merged[\"y\"], merged[\"yhat\"])\n",
    "    scores[\"name\"] = name\n",
    "    scores[\"matched_rows\"] = len(merged)\n",
    "    results[name] = scores\n",
    "\n",
    "    print(f\"  {name}: WAPE={scores['wape']:.2%}, MAE={scores['mae']:.2f}, Bias={scores['bias']:.2f}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baselines (fast, no features needed) ---\n",
    "\n",
    "train_base = train[[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "test_base = test[[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "\n",
    "print(\"Running baseline models...\\n\")\n",
    "\n",
    "# 1. Naive (last value repeated)\n",
    "score_model(\"Naive\", NaiveForecaster(), train_base, test_base, HORIZON)\n",
    "\n",
    "# 2. Moving Average (4-week window)\n",
    "score_model(\"MA(4)\", MovingAverageForecaster(window=4), train_base, test_base, HORIZON)\n",
    "\n",
    "# 3. Moving Average (8-week window)\n",
    "score_model(\"MA(8)\", MovingAverageForecaster(window=8), train_base, test_base, HORIZON)\n",
    "\n",
    "# 4. Moving Average (13-week window = 1 quarter)\n",
    "score_model(\"MA(13)\", MovingAverageForecaster(window=13), train_base, test_base, HORIZON)\n",
    "\n",
    "# 5. Seasonal Naive (same week last year) - needs 52+ weeks of history\n",
    "score_model(\"SeasonalNaive(52)\", SeasonalNaiveForecaster(season_length=52), train_base, test_base, HORIZON)\n",
    "\n",
    "# 6. ETS (Exponential Smoothing - auto-selects best spec)\n",
    "score_model(\"ETS\", ETSForecaster(season_length=52), train_base, test_base, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick check: How do baselines compare to your existing predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Model':<25} {'WAPE':>8} {'MAE':>8} {'vs Benchmark':>14}\")\n",
    "print(\"-\" * 57)\n",
    "print(f\"{'Your Predictions':<25} {benchmark_wape:>8.2%} {benchmark_mae:>8.2f} {'baseline':>14}\")\n",
    "print(\"-\" * 57)\n",
    "for name, scores in sorted(results.items(), key=lambda x: x[1][\"wape\"]):\n",
    "    delta = scores[\"wape\"] - benchmark_wape\n",
    "    arrow = \"+\" if delta > 0 else \"\"\n",
    "    print(f\"{name:<25} {scores['wape']:>8.2%} {scores['mae']:>8.2f} {arrow}{delta:>13.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ML Models (LightGBM, XGBoost, CatBoost)\n",
    "\n",
    "These need feature engineering. The library handles this for you, including your fiscal calendar features.\n",
    "\n",
    "### 3a. Configure features with your fiscal calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.models import LightGBMForecaster, XGBoostForecaster, CatBoostForecaster\n",
    "\n",
    "# Feature config - the fiscal_config here is only used if you DON'T pass a\n",
    "# pre-built fiscal_calendar. Since we have our own calendar, we'll pass it\n",
    "# directly to engineer_features and the ML models will pick it up.\n",
    "#\n",
    "# But we still set a config so the FeatureConfig dataclass is happy:\n",
    "feature_config = FeatureConfig(\n",
    "    lags=[1, 2, 4, 8, 13, 26, 52],\n",
    "    rolling_windows=[4, 13, 26, 52],\n",
    "    rolling_aggs=[\"mean\", \"std\"],\n",
    "    diff_periods=[1, 4, 52],\n",
    "    pct_change_periods=[1, 52],\n",
    "    include_expanding=True,\n",
    "    fiscal_config=FiscalCalendarConfig(),  # placeholder, we override with our calendar\n",
    "    include_calendar_features=True,\n",
    ")\n",
    "\n",
    "print(\"Feature config ready.\")\n",
    "print(f\"  Lags: {feature_config.lags}\")\n",
    "print(f\"  Rolling windows: {feature_config.rolling_windows}\")\n",
    "print(f\"  Total features: ~33 numeric + fiscal + calendar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Preview the engineered features\n",
    "\n",
    "Run this on a small sample first to verify everything looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview features on a small sample\n",
    "sample_ids = train[\"unique_id\"].unique()[:3]\n",
    "sample = train[train[\"unique_id\"].isin(sample_ids)][[\"unique_id\", \"ds\", \"y\"]].copy()\n",
    "\n",
    "sample_feat = engineer_features(\n",
    "    sample,\n",
    "    config=feature_config,\n",
    "    fiscal_calendar=fiscal_cal,  # <-- YOUR fiscal calendar\n",
    ")\n",
    "\n",
    "print(f\"Columns ({len(sample_feat.columns)}):\")\n",
    "print(sample_feat.columns.tolist())\n",
    "print(f\"\\nShape: {sample_feat.shape}\")\n",
    "print(f\"NaN rows (from lag warmup): {sample_feat.isna().any(axis=1).sum()}\")\n",
    "\n",
    "# Check fiscal features look right\n",
    "fiscal_preview = sample_feat[[\"ds\", \"fiscal_year\", \"fiscal_quarter\", \"fiscal_month\",\n",
    "                               \"fiscal_week\", \"is_fiscal_month_end\"]].drop_duplicates(\"ds\").tail(10)\n",
    "print(\"\\nFiscal feature preview (last 10 weeks):\")\n",
    "fiscal_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Train ML models\n",
    "\n",
    "Note: The ML forecasters call `engineer_features` internally. We pass our fiscal\n",
    "calendar through the model's feature_config. However, since the models generate\n",
    "the calendar internally from the config, and we want to use **our own** calendar,\n",
    "we need to merge fiscal features onto the data **before** passing it to the models,\n",
    "then tell the model not to regenerate them.\n",
    "\n",
    "**Strategy**: Pre-merge fiscal features from your calendar, then let the ML\n",
    "models add the lag/rolling features on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-merge fiscal features from YOUR calendar onto train and test\n",
    "train_with_fiscal = add_fiscal_features(train[[\"unique_id\", \"ds\", \"y\"]], fiscal_calendar=fiscal_cal)\n",
    "test_with_fiscal = add_fiscal_features(test[[\"unique_id\", \"ds\", \"y\"]], fiscal_calendar=fiscal_cal)\n",
    "\n",
    "print(f\"Train with fiscal: {train_with_fiscal.shape}\")\n",
    "print(f\"Test with fiscal: {test_with_fiscal.shape}\")\n",
    "print(f\"\\nFiscal columns added: {[c for c in train_with_fiscal.columns if 'fiscal' in c.lower()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightGBM (Tweedie) ---\n",
    "print(\"Training LightGBM (Tweedie)...\")\n",
    "lgb_model = LightGBMForecaster(\n",
    "    feature_config=feature_config,\n",
    "    use_tweedie=True,\n",
    "    strategy=\"recursive\",\n",
    ")\n",
    "score_model(\"LightGBM\", lgb_model, train_with_fiscal, test_with_fiscal, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost ---\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = XGBoostForecaster(\n",
    "    feature_config=feature_config,\n",
    "    strategy=\"recursive\",\n",
    ")\n",
    "score_model(\"XGBoost\", xgb_model, train_with_fiscal, test_with_fiscal, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CatBoost ---\n",
    "print(\"Training CatBoost...\")\n",
    "cat_model = CatBoostForecaster(\n",
    "    feature_config=feature_config,\n",
    ")\n",
    "score_model(\"CatBoost\", cat_model, train_with_fiscal, test_with_fiscal, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Direct forecasting variant\n",
    "\n",
    "Direct strategy trains a **separate model for each horizon step** (week 1, week 2, ...).  \n",
    "Avoids error accumulation from recursive predictions. The M5 1st place used both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightGBM Direct ---\n",
    "print(f\"Training LightGBM Direct (one model per week, {HORIZON} models)...\")\n",
    "lgb_direct = LightGBMForecaster(\n",
    "    feature_config=feature_config,\n",
    "    use_tweedie=True,\n",
    "    strategy=\"direct\",\n",
    ")\n",
    "lgb_direct.fit(train_with_fiscal, horizon=HORIZON)\n",
    "preds_direct = lgb_direct.predict(horizon=HORIZON)\n",
    "\n",
    "merged_direct = test_with_fiscal.merge(preds_direct, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "scores_direct = evaluate_forecast(merged_direct[\"y\"], merged_direct[\"yhat\"])\n",
    "scores_direct[\"name\"] = \"LightGBM (Direct)\"\n",
    "scores_direct[\"matched_rows\"] = len(merged_direct)\n",
    "results[\"LightGBM (Direct)\"] = scores_direct\n",
    "print(f\"  LightGBM (Direct): WAPE={scores_direct['wape']:.2%}, MAE={scores_direct['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Advanced Models\n",
    "\n",
    "### 4a. Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.models import ProphetForecaster\n",
    "\n",
    "print(\"Training Prophet...\")\n",
    "prophet_model = ProphetForecaster(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    ")\n",
    "score_model(\"Prophet\", prophet_model, train_base, test_base, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Intermittent demand models\n",
    "\n",
    "If your demand classification showed a lot of intermittent/lumpy series,  \n",
    "these specialized models may outperform on those series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.models import CrostonForecaster, SBAForecaster, TSBForecaster\n",
    "\n",
    "print(\"Training intermittent demand models...\\n\")\n",
    "\n",
    "score_model(\"Croston\", CrostonForecaster(), train_base, test_base, HORIZON)\n",
    "score_model(\"SBA\", SBAForecaster(), train_base, test_base, HORIZON)\n",
    "score_model(\"TSB\", TSBForecaster(), train_base, test_base, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. DRFAM Ensemble (M5 1st Place approach)\n",
    "\n",
    "Averages Direct and Recursive forecasts from the same model class.  \n",
    "This is the strategy used by the M5 competition winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.models import DRFAMEnsemble\n",
    "\n",
    "print(f\"Training DRFAM (Direct + Recursive averaging)...\")\n",
    "drfam = DRFAMEnsemble(\n",
    "    model_class=LightGBMForecaster,\n",
    "    model_params={\"feature_config\": feature_config, \"use_tweedie\": True},\n",
    "    use_direct=True,\n",
    "    use_recursive=True,\n",
    ")\n",
    "drfam.fit(train_with_fiscal, horizon=HORIZON)\n",
    "preds_drfam = drfam.predict(horizon=HORIZON)\n",
    "\n",
    "merged_drfam = test_with_fiscal.merge(preds_drfam, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "scores_drfam = evaluate_forecast(merged_drfam[\"y\"], merged_drfam[\"yhat\"])\n",
    "scores_drfam[\"name\"] = \"DRFAM (LightGBM)\"\n",
    "scores_drfam[\"matched_rows\"] = len(merged_drfam)\n",
    "results[\"DRFAM (LightGBM)\"] = scores_drfam\n",
    "print(f\"  DRFAM: WAPE={scores_drfam['wape']:.2%}, MAE={scores_drfam['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Ensemble Models\n",
    "\n",
    "Combine multiple models. Often the best approach in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.models import SimpleEnsemble, WeightedEnsemble, StackingEnsemble\n",
    "\n",
    "# Base models for ensembles\n",
    "ensemble_models = [\n",
    "    LightGBMForecaster(feature_config=feature_config, use_tweedie=True),\n",
    "    XGBoostForecaster(feature_config=feature_config),\n",
    "    CatBoostForecaster(feature_config=feature_config),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simple Ensemble (equal average) ---\n",
    "print(\"Training Simple Ensemble (equal weights)...\")\n",
    "simple_ens = SimpleEnsemble(models=ensemble_models)\n",
    "score_model(\"SimpleEnsemble\", simple_ens, train_with_fiscal, test_with_fiscal, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Weighted Ensemble (learns weights from CV) ---\n",
    "print(\"Training Weighted Ensemble (CV-optimized weights)...\")\n",
    "weighted_ens = WeightedEnsemble(\n",
    "    models=[\n",
    "        LightGBMForecaster(feature_config=feature_config, use_tweedie=True),\n",
    "        XGBoostForecaster(feature_config=feature_config),\n",
    "        CatBoostForecaster(feature_config=feature_config),\n",
    "    ],\n",
    "    cv_folds=3,\n",
    "    metric=\"wape\",\n",
    ")\n",
    "score_model(\"WeightedEnsemble\", weighted_ens, train_with_fiscal, test_with_fiscal, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stacking Ensemble (meta-learner) ---\n",
    "print(\"Training Stacking Ensemble (Ridge meta-learner)...\")\n",
    "stacking_ens = StackingEnsemble(\n",
    "    models=[\n",
    "        LightGBMForecaster(feature_config=feature_config, use_tweedie=True),\n",
    "        XGBoostForecaster(feature_config=feature_config),\n",
    "        CatBoostForecaster(feature_config=feature_config),\n",
    "    ],\n",
    "    cv_folds=3,\n",
    ")\n",
    "score_model(\"StackingEnsemble\", stacking_ens, train_with_fiscal, test_with_fiscal, HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Hierarchical Reconciliation\n",
    "\n",
    "Your hierarchy:\n",
    "```\n",
    "Total\n",
    "└── Parent Customer\n",
    "    └── Customer\n",
    "        └── Profit Center\n",
    "            └── Material\n",
    "                └── unique_id (Customer_Material)\n",
    "```\n",
    "\n",
    "Reconciliation ensures forecasts **sum correctly up the hierarchy**.  \n",
    "Bottom-up is simplest: forecast at the granular level, aggregate up.  \n",
    "MinTrace is optimal: adjusts all levels to minimize total error.\n",
    "\n",
    "**Note**: This section requires that your data has the hierarchy columns  \n",
    "(`parent_customer_id`, `customer_id`, `profit_center_id`, `material_id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds_timeseries.reconciliation.hierarchy import HierarchySpec, create_hierarchy_from_data\n",
    "from ds_timeseries.reconciliation.methods import reconcile_forecasts\n",
    "\n",
    "# === EDIT THIS: Define your hierarchy (bottom to top) ===\n",
    "# List columns from most granular to most aggregated\n",
    "\n",
    "hierarchy_cols = [\n",
    "    \"material_id\",          # Most granular (within a customer)\n",
    "    \"profit_center_id\",     # Profit Center groups materials\n",
    "    \"customer_id\",          # Customer groups profit centers\n",
    "    \"parent_customer_id\",   # Parent Customer groups customers\n",
    "]\n",
    "\n",
    "# Check which columns actually exist in your data\n",
    "available = [c for c in hierarchy_cols if c in train.columns]\n",
    "missing = [c for c in hierarchy_cols if c not in train.columns]\n",
    "\n",
    "if missing:\n",
    "    print(f\"Missing hierarchy columns: {missing}\")\n",
    "    print(f\"Available: {available}\")\n",
    "    print(f\"Skipping reconciliation - add these columns to your data or adjust the list above.\")\n",
    "else:\n",
    "    hierarchy = HierarchySpec(levels=available, bottom_level=\"unique_id\")\n",
    "    print(f\"Hierarchy defined: {' > '.join(reversed(available))} > unique_id\")\n",
    "    print(f\"Bottom-level series: {train['unique_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bottom-level forecasts from best model so far\n",
    "# (Re-use whichever performed best above)\n",
    "\n",
    "best_model_name = min(results, key=lambda k: results[k][\"wape\"])\n",
    "print(f\"Using best model for reconciliation: {best_model_name}\")\n",
    "\n",
    "# Re-fit the best model and get predictions\n",
    "# (We need the raw predictions DataFrame, not just scores)\n",
    "best_model = LightGBMForecaster(feature_config=feature_config, use_tweedie=True)\n",
    "best_model.fit(train_with_fiscal)\n",
    "bottom_preds = best_model.predict(horizon=HORIZON)\n",
    "\n",
    "print(f\"Bottom-level predictions: {len(bottom_preds)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build aggregation matrix and reconcile\n",
    "if not missing:  # only if hierarchy columns exist\n",
    "    # Need hierarchy columns in the data for building the matrix\n",
    "    train_hier = train[[\"unique_id\", \"ds\", \"y\"] + available].copy()\n",
    "    test_hier = test[[\"unique_id\", \"ds\", \"y\"] + available].copy()\n",
    "\n",
    "    hierarchy.build_aggregation_matrix(train_hier)\n",
    "\n",
    "    # Bottom-Up reconciliation\n",
    "    reconciled_bu = reconcile_forecasts(\n",
    "        bottom_preds, test_hier, hierarchy, method=\"bottom_up\"\n",
    "    )\n",
    "    print(f\"Bottom-Up reconciled: {len(reconciled_bu)} rows across all levels\")\n",
    "\n",
    "    # Score at bottom level (same as unreconciled for bottom-up)\n",
    "    recon_bottom = reconciled_bu[reconciled_bu[\"level\"] == \"unique_id\"]\n",
    "    recon_merged = test_hier.merge(\n",
    "        recon_bottom[[\"unique_id\", \"ds\", \"yhat\"]], on=[\"unique_id\", \"ds\"], how=\"inner\"\n",
    "    )\n",
    "    print(f\"  Bottom-Up WAPE: {wape(recon_merged['y'], recon_merged['yhat']):.2%}\")\n",
    "\n",
    "    # MinTrace reconciliation (optimal)\n",
    "    try:\n",
    "        reconciled_mt = reconcile_forecasts(\n",
    "            bottom_preds, test_hier, hierarchy, method=\"ols\"\n",
    "        )\n",
    "        mt_bottom = reconciled_mt[reconciled_mt[\"level\"] == \"unique_id\"]\n",
    "        mt_merged = test_hier.merge(\n",
    "            mt_bottom[[\"unique_id\", \"ds\", \"yhat\"]], on=[\"unique_id\", \"ds\"], how=\"inner\"\n",
    "        )\n",
    "        print(f\"  MinTrace (OLS) WAPE: {wape(mt_merged['y'], mt_merged['yhat']):.2%}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  MinTrace failed (may need more data): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Final Scorecard: All Models vs Your Predictions\n",
    "\n",
    "The moment of truth. Every model scored against the same test period,  \n",
    "compared to your existing predictions from November 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scorecard\n",
    "scorecard = pd.DataFrame(results).T\n",
    "\n",
    "# Add benchmark row\n",
    "benchmark_row = pd.DataFrame([{\n",
    "    \"name\": \"YOUR PREDICTIONS\",\n",
    "    \"wape\": benchmark_wape,\n",
    "    \"mae\": benchmark_mae,\n",
    "    \"rmse\": np.nan,\n",
    "    \"bias\": np.nan,\n",
    "    \"matched_rows\": len(benchmark),\n",
    "}])\n",
    "scorecard = pd.concat([benchmark_row, scorecard], ignore_index=True)\n",
    "\n",
    "# Sort by WAPE\n",
    "scorecard = scorecard.sort_values(\"wape\").reset_index(drop=True)\n",
    "scorecard[\"rank\"] = range(1, len(scorecard) + 1)\n",
    "\n",
    "# Add comparison to benchmark\n",
    "scorecard[\"wape_vs_benchmark\"] = scorecard[\"wape\"] - benchmark_wape\n",
    "scorecard[\"wape_improvement_%\"] = -(scorecard[\"wape_vs_benchmark\"] / benchmark_wape * 100)\n",
    "\n",
    "display_cols = [\"rank\", \"name\", \"wape\", \"mae\", \"bias\", \"wape_improvement_%\"]\n",
    "display_cols = [c for c in display_cols if c in scorecard.columns]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL SCORECARD\")\n",
    "print(f\"Test period: {test['ds'].min().date()} to {test['ds'].max().date()} ({HORIZON} weeks)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "scorecard[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "try:\n",
    "    import plotly.express as px\n",
    "\n",
    "    fig = px.bar(\n",
    "        scorecard.sort_values(\"wape\"),\n",
    "        x=\"wape\",\n",
    "        y=\"name\",\n",
    "        orientation=\"h\",\n",
    "        title=f\"Model Comparison: WAPE (lower is better) - {HORIZON}-week test\",\n",
    "        labels={\"wape\": \"WAPE\", \"name\": \"\"},\n",
    "        color=\"wape\",\n",
    "        color_continuous_scale=\"RdYlGn_r\",\n",
    "    )\n",
    "    # Add vertical line for benchmark\n",
    "    fig.add_vline(x=benchmark_wape, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=\"Your Predictions\")\n",
    "    fig.update_layout(height=max(400, len(scorecard) * 35), showlegend=False)\n",
    "    fig.show()\n",
    "except ImportError:\n",
    "    print(\"Install plotly for interactive charts: pip install plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Roll Up to Fiscal Months\n",
    "\n",
    "Leadership often wants to see accuracy at the **fiscal month** level, not weekly.  \n",
    "Use `rollup_to_fiscal_month` with **your own** fiscal calendar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the best model\n",
    "best_name = scorecard.loc[scorecard[\"name\"] != \"YOUR PREDICTIONS\"].iloc[0][\"name\"]\n",
    "print(f\"Best model: {best_name}\")\n",
    "\n",
    "# Re-generate predictions for rollup\n",
    "best_model = LightGBMForecaster(feature_config=feature_config, use_tweedie=True)\n",
    "best_model.fit(train_with_fiscal)\n",
    "best_preds = best_model.predict(horizon=HORIZON)\n",
    "\n",
    "# Merge actuals + predictions for rollup\n",
    "test_merged = test[[\"unique_id\", \"ds\", \"y\"]].merge(\n",
    "    best_preds[[\"unique_id\", \"ds\", \"yhat\"]], on=[\"unique_id\", \"ds\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "# Roll up to fiscal months using YOUR calendar\n",
    "monthly = rollup_to_fiscal_month(\n",
    "    test_merged,\n",
    "    value_cols=[\"y\", \"yhat\"],\n",
    "    fiscal_calendar=fiscal_cal,  # <-- YOUR fiscal calendar\n",
    ")\n",
    "\n",
    "# Monthly WAPE\n",
    "complete = monthly[monthly[\"is_complete\"]]\n",
    "print(f\"\\nMonthly WAPE (complete months only):\")\n",
    "for _, row in complete.groupby([\"fiscal_year\", \"fiscal_month\"]).agg(\n",
    "    {\"y\": \"sum\", \"yhat\": \"sum\"}\n",
    ").iterrows():\n",
    "    m_wape = abs(row[\"y\"] - row[\"yhat\"]) / abs(row[\"y\"]) if row[\"y\"] != 0 else float(\"inf\")\n",
    "    print(f\"  FY{_[0]} M{_[1]:02d}: WAPE={m_wape:.2%}  (actual={row['y']:,.0f}, forecast={row['yhat']:,.0f})\")\n",
    "\n",
    "overall_monthly_wape = wape(complete[\"y\"], complete[\"yhat\"])\n",
    "print(f\"\\n  Overall monthly WAPE: {overall_monthly_wape:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Neural Models (Optional)\n",
    "\n",
    "Requires `neuralforecast` to be installed: `pip install neuralforecast`  \n",
    "These are heavier, slower, and may not beat gradient boosting on tabular data.  \n",
    "But worth trying, especially TFT for long horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ds_timeseries.models.neural import (\n",
    "        NBEATSForecaster,\n",
    "        NHITSForecaster,\n",
    "        NeuralConfig,\n",
    "    )\n",
    "\n",
    "    neural_config = NeuralConfig(\n",
    "        input_size=52,       # look back 52 weeks\n",
    "        max_steps=500,       # training steps\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=32,\n",
    "        accelerator=\"auto\",  # \"gpu\" if you have one, else \"cpu\"\n",
    "    )\n",
    "\n",
    "    print(\"Training N-BEATS...\")\n",
    "    nbeats = NBEATSForecaster(horizon=HORIZON, config=neural_config)\n",
    "    score_model(\"N-BEATS\", nbeats, train_base, test_base, HORIZON)\n",
    "\n",
    "    print(\"Training N-HITS...\")\n",
    "    nhits = NHITSForecaster(horizon=HORIZON, config=neural_config)\n",
    "    score_model(\"N-HITS\", nhits, train_base, test_base, HORIZON)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"neuralforecast not installed. Skipping neural models.\")\n",
    "    print(\"Install with: pip install neuralforecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Hyperparameter Tuning (Optional)\n",
    "\n",
    "Once you've identified the top 1-2 model types, tune them for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from ds_timeseries.models.tuning import tune_lightgbm, tune_xgboost\n\n# Only tune on training data (uses internal time-series CV, no leakage)\nprint(\"Tuning LightGBM (this may take a while)...\")\ntune_result = tune_lightgbm(\n    train_with_fiscal,\n    feature_config=feature_config,\n    n_iter=20,    # number of random configurations to try\n    n_folds=3,\n)\n\nprint(f\"\\nBest params: {tune_result.best_params}\")\nprint(f\"Best CV WAPE: {tune_result.best_score:.2%}\")\n\n# Score tuned model on the real test set\nif tune_result.best_model:\n    score_model(\"LightGBM (Tuned)\", tune_result.best_model, train_with_fiscal, test_with_fiscal, HORIZON)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference: Adapting to Your Data\n",
    "\n",
    "### Checklist\n",
    "\n",
    "| Step | What to Change | Where |\n",
    "|------|---------------|-------|\n",
    "| Load data | File path and format | Section 1a |\n",
    "| Column mapping | Rename your columns to `unique_id`, `ds`, `y` | Section 1b |\n",
    "| Fiscal calendar | Load your table, map columns, derive missing flags | Section 1c |\n",
    "| Cutoff date | Set `CUTOFF_DATE` to your FY start | Section 1e |\n",
    "| Benchmark | Load your existing predictions | Section 1f |\n",
    "| Hierarchy columns | Edit `hierarchy_cols` list | Section 6 |\n",
    "\n",
    "### Hierarchy Notes\n",
    "\n",
    "**Your business hierarchy:**\n",
    "```\n",
    "Total\n",
    "└── Parent Customer   →  parent_customer_id\n",
    "    └── Customer       →  customer_id\n",
    "        └── Profit Center  →  profit_center_id\n",
    "            └── Material   →  material_id\n",
    "                └── Customer_Material  →  unique_id\n",
    "```\n",
    "\n",
    "**Key points:**\n",
    "- `unique_id` = `customer_id` + `_` + `material_id` (the bottom level)\n",
    "- The hierarchy defines how forecasts **aggregate up**\n",
    "- Material rolls up to Profit Center (product dimension)\n",
    "- Customer rolls up to Parent Customer (customer dimension)\n",
    "- This is a **cross-hierarchy** (product x customer), which is more complex than a simple tree\n",
    "- For cross-hierarchies, you may want to reconcile each dimension separately,\n",
    "  or flatten to a single tree by combining: `Parent Customer > Customer > Profit Center > Material`\n",
    "\n",
    "### Fiscal Calendar Notes\n",
    "\n",
    "**What you bring:**\n",
    "- Your fiscal calendar table with dates, week-end dates, fiscal months, etc.\n",
    "- The `ds` column in your calendar MUST match the `ds` dates in your sales data exactly\n",
    "\n",
    "**What the library derives if missing:**\n",
    "- `fiscal_week_in_month`: cumulative count of weeks per fiscal month\n",
    "- `fiscal_week_in_quarter`: cumulative count of weeks per fiscal quarter\n",
    "- `is_fiscal_month_end`: last week in each fiscal month (drives hockey-stick detection)\n",
    "- `is_fiscal_quarter_end`, `is_fiscal_year_end`: period boundary flags\n",
    "\n",
    "**Why `is_fiscal_month_end` matters:**  \n",
    "Sales surge at fiscal period ends (the \"hockey stick\"). This boolean flag lets ML models\n",
    "learn that pattern directly. It's typically the single most important fiscal feature.\n",
    "\n",
    "### Train/Test Split Notes\n",
    "\n",
    "- The split is at your FY start (Nov 25) - all models see the same history\n",
    "- No cross-validation on the test period - that's your holdout for honest comparison\n",
    "- Cross-validation happens **within training data only** (for tuning & weighted ensembles)\n",
    "- This mirrors a real production scenario: train on history, forecast the fiscal year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scorecard for reference\n",
    "scorecard.to_csv(\"../data/raw/model_scorecard.csv\", index=False)\n",
    "print(\"Scorecard saved to data/raw/model_scorecard.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}